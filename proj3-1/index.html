<html>

<head>
	<style>
		body {
			font-family: 'Trebuchet MS', sans-serif;
			text-align: center;
		}

		h3 {
			font-style: italic;
		}
	</style>
</head>

<body>
	<h1>CS184 Project 3-1</h1>
	<h1>Lucas Huang :: Frank Cuoco</h1>
	<h2>Overview</h2>
	<p>Isussy sysysysys</p>
	<h2>Part 1</h2>
	<p>Our ray tracing algorithm uses rays starting from a “camera” going into our space to emulate light running through an
	image. We use the ray equation r(t) = o + td, where o is the coordinates of the camera, d is the unit vector following
	along the ray’s direction as found using the coordinates from the Assignment 3-1 spec, and t is a double that traces the
	points of the ray between min_t and max_t values defining its bounds.</p>
	<p>To sample pixels, we take in input coordinates (x, y) for the bottom-left corner of a pixel, and rescale it relative to
	the width and height of the image by generating rays offset from (x,y) by an an amount generated by our grid sampler.
	The number of times we do this is determined by a num_samples variable. We estimate the global radiance illumination of
	the ray, by taking the mean of the values calculated for each ray.</p>
	<p>Primitives are mathematical objects that have equations defining them, such as triangles on a plane and spheres. To
	calculate our intersection between rays and primitives, we use the equations of a given ray and primitive and solve for
	t. If t exists between the bounds of the ray, we have found the intersection point; otherwise, the ray does not
	intersect the primitive. The Möller–Trumbore algorithm is an efficient way of finding intersections between triangles
	and rays, and is what we have used to calculate our intersection. The algorithm is solved from first setting the ray
	equation and barycentric triangle coordinates equal, o + td = (1-n1-n2) * p0 + n1p1 + n2p2; five new vectors, e1, e2, s,
	s1, and s2 are defined off of those algorithms to perform the algorithm. Using Möller–Trumbore minimizes the total
	arithmetic operations necessary to calculate the intersection on a hardware level.</p>
	<img src='./images/1-CBempty.png'>
	<img src='./images/1-CBgems.png'>
	<img src='./images/1-CBspheres.png'>
	<p>Above, we see renderings of the files CBempty, CBgems, and CBspheres using normal shading.</p>
	<p><i>Dev comments: Working with Möller–Trumbore in our code base, the variable numbers for n and p are indexed to 1 rather than 0, leading to some misshading of our meshes at first.</i><p>

	<h2>Part 2</h2>
	<p>Our BVH (bounding volume hierarchy) tree construction algorithm is as follows: For each node, find the bounding box of
	the node. If our number of primitives in the node is below the maximum leaf size, we return the node. Else, we start a
	recursive case. We determine what the largest dimension is to create left and right subnodes. Along that axis, we chose
	to look at the average of all the centroids of the primitives, Half of the primitives go into a left node, and the other
	half goes into a right node. The two nodes individually run the algorithm again from the top.</p>
	<p>Below, we see the renderings of Max Planck, beast, and Lucy. These renders are large enough that they do not render in a reasonable timefrme without using BVH acceleration.</p>
	<img src='./images/2-maxplanck.png'>
	<img src='./images/2-beast.png'>
	<img src='./images/2-CBlucy.png'>
	<p>The rendering of maxplanck, beast, and CBlucy uses 50801, 64618, and 133796 primitives respectively, takes 0.1230, 0.0551, and 0.1777 seconds to render with BVH, and takes over 20, 22, and 30 minutes to render without BVH.</p>
	<p>When rendering with BVHs, our render time increases marginally with an increase in number of primitives, while without BVHs, rendering time sharply and proportionally increases when our number of primitives increase. When rendering with BVHs, we only ever need to check a small number of intersections for each ray, due to the max number of primitives in each BVH node that we check; the number of BVH nodes increases logarithmically for a linear increase in number of primitives, leading to its more stunted growth.</p>
	<p><i>Dev comments: BVH was mostly straightforward. An issue with C++ variable definitions led us to use an undefined int in our code, resulting in memory issues before being resolved.</i></p>

	<h2>Part 3</h2>
	<p>For uniform hemisphere sampling, we take a random direction from a hemisphere, create a ray going outward, and test if
	there is an intersection with another primitive. If there is, we add the calculated radiance for calculation using the
	Monte Carlo estimation method. This equation is given as follows, from the project spec.</p>
	<img src='./images/3-equation.png' width='100'>
	<p>Our uniform light sampling cycles through our scene lights. For point lights, we take one sample; area lights will have
	a number of samples determined by num_samples. For each sample, we obtain an angle, distance for radiance, and pdf using
	sample_L. The Monte Carlo formula is as it was with uniform hemisphere sampling. Avoiding objects in the wrong direction
	from our light source, we do a cos_theta check to guarantee we only proceed with applying Monte Carlo on objects with
	valid intersections. We have min_t and max_t variables to ensure that we avoid floating point errors with the object
	that we are shooting the ray from itself, or objects behind other objects.</p>
	<p>Below are bunny and coil meshes rendered with uniform hemisphere sampling.</p>
	<img src='./images/3-bunny_hemisphere.png'>
	<img src='./images/3-coil_hemisphere.png'>
	<p>Below are bunny and coil meshes rendered with lighting importance sampling.</p>
	<img src='./images/3-bunny_importance.png'>
	<img src='./images/3-coil_importance.png'>
	<p>Below is the bunny scene rendered with 1, 4, 16, and 64 light rays respectively when using light sampling.</p>
	<img src='./images/3-bunny1.png'>
	<img src='./images/3-bunny4.png'>
	<img src='./images/3-bunny16.png'>
	<img src='./images/3-bunny64.png'>
	<p>Uniform hemisphere sampling creates more uncertainty, as rays may not reach light sources. Point lights do not work with
	this form of sampling. Light importance sampling makes use of our knowledge of light sources to guarantee ray
	intersections with light sources giving us more valuable radiance data to work with and reduces noise. As rays come out
	of lights now, point lights are able to be factored in for the rendering of meshes.</p>
	<p><i>Dev comments: Working out when to use inputs from the object space or the world space had resulted in the vast amount of issues in this part. Be careful when thinking about rays!</i></p>


	<h2>Part 4</h2>
	<p>In our implementation of indirect lighting, we use Russian Roulette estimation, where we may get a fair estimate of our
	lighting. Our implementation runs recursively, where we use a pdf to determine if a ray continues bouncing or calls
	one_bounce_radiance marking our final bounce. A depth variable introduced maintains an internal count for how many
	bounces the ray has gone through and returns 0 when we have reached our max_ray_depth.</p>
	<p>Below, we see our bunny as ran using indirect lighting.</p>
	<img src='./images/4-bunny0.png'>

	<h2>Part 5</h2>

	<p>Our webpage is at https://cal-cs184-student.github.io/sp22-project-webpages-Lukatastic/proj3-1/index.html</p>
</body>

</html>